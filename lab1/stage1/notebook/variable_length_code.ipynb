{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用可变长度编码压缩倒排索引表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Zhenyu Bo\n",
    "# Date: 2024-11-07\n",
    "\n",
    "\"\"\"\n",
    "压缩倒排索引表并拆分为词典和倒排表文件。\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "def variable_byte_encode(gaps: list[int]) -> bytes:\n",
    "    \"\"\"\n",
    "    使用可变字节编码（Variable Byte Encoding）对文档间距进行压缩。\n",
    "\n",
    "    参数：\n",
    "    - gaps: 文档间距列表。\n",
    "\n",
    "    返回：\n",
    "    - 压缩后的字节序列。\n",
    "    \"\"\"\n",
    "    encoded_bytes = []\n",
    "    for gap in gaps:\n",
    "        byte_chunks = []\n",
    "        while gap >= 128:\n",
    "            byte_chunks.append(gap % 128)\n",
    "            gap = gap // 128\n",
    "        byte_chunks.append(gap + 128)  # 设置最后一个字节的最高位为1\n",
    "        # 由于要按大端顺序存储，反转字节顺序\n",
    "        byte_chunks = byte_chunks[::-1]\n",
    "        encoded_bytes.extend(byte_chunks)\n",
    "    return bytes(encoded_bytes)\n",
    "\n",
    "def calculate_gaps(index_list: list[int]) -> list[int]:\n",
    "    \"\"\"\n",
    "    计算文档间距列表。\n",
    "\n",
    "    假设输入的 `index_list` 是一个递增的文档 ID 列表，返回每个文档 ID 与前一个文档 ID 之间的差值列表。\n",
    "\n",
    "    参数：\n",
    "    - index_list: 递增的文档 ID 列表。\n",
    "\n",
    "    返回：\n",
    "    - 文档间距列表。\n",
    "    \"\"\"\n",
    "    gaps = []\n",
    "    previous_id = 0  # 假设第一个文档的前一个 ID 为 0\n",
    "\n",
    "    for doc_id in index_list:\n",
    "        gap = doc_id - previous_id\n",
    "        gaps.append(gap)\n",
    "        previous_id = doc_id\n",
    "\n",
    "    return gaps\n",
    "\n",
    "\n",
    "def compress(index_list: list[int]) -> bytes:\n",
    "    \"\"\"\n",
    "    压缩文档 ID 列表为字节序列。\n",
    "\n",
    "    使用文档间距替代 ID 并应用可变字节编码进行压缩。\n",
    "\n",
    "    参数：\n",
    "    - index_list: 递增的文档 ID 列表。\n",
    "\n",
    "    返回：\n",
    "    - 压缩后的字节序列。\n",
    "    \"\"\"\n",
    "    # 计算文档间距\n",
    "    gaps = calculate_gaps(index_list)\n",
    "\n",
    "    # 使用可变字节编码压缩间距列表\n",
    "    compressed_data = variable_byte_encode(gaps)\n",
    "\n",
    "    return compressed_data\n",
    "\n",
    "\n",
    "def save_compressed_data(csv_file_path: str, compressed_file_path: str, vocabulary_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    保存压缩后的倒排索引和词汇表。\n",
    "\n",
    "    参数：\n",
    "    - csv_file_path: 生成的倒排索引 CSV 文件路径（例如 \"book_inverted_index_table.csv\"）。\n",
    "    - compressed_file_path: 压缩后的倒排表二进制文件路径。\n",
    "    - vocabulary_file_path: 词汇表文件路径，包含词项及其在倒排表中的字节偏移量和长度。\n",
    "    \"\"\"\n",
    "    # vocabulary = []\n",
    "    current_offset = 0\n",
    "\n",
    "    try:\n",
    "        with open(compressed_file_path, \"wb\") as f_bin, \\\n",
    "             open(vocabulary_file_path, \"w\", encoding=\"UTF-8\", newline='') as f_vocab, \\\n",
    "             open(csv_file_path, \"r\", encoding=\"UTF-8\") as f_csv:\n",
    "\n",
    "            csv_reader = csv.DictReader(f_csv)\n",
    "            vocab_writer = csv.writer(f_vocab)\n",
    "            # 写入词汇表的表头\n",
    "            vocab_writer.writerow(['word', 'offset', 'length'])\n",
    "\n",
    "            for row in csv_reader:\n",
    "                word = row['word']\n",
    "                # 解析 id_list（假设以列表字符串形式存储）\n",
    "                id_list_str = row['id_list']\n",
    "                id_list = json.loads(id_list_str)\n",
    "\n",
    "                # 压缩文档 ID 列表\n",
    "                compressed_bytes = compress(id_list)\n",
    "\n",
    "                # 写入倒排表\n",
    "                f_bin.write(compressed_bytes)\n",
    "\n",
    "                # 记录词典信息\n",
    "                vocab_writer.writerow([word, current_offset, len(compressed_bytes)])\n",
    "                current_offset += len(compressed_bytes)\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"文件操作失败: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON 解码失败: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# 处理书籍倒排索引表\n",
    "csv_file_path = \"../book_inverted_index_table.csv\"\n",
    "compressed_file_path = \"../data/book_inverted_index_compressed.bin\"\n",
    "vocabulary_file_path = \"../data/book_vocabulary.csv\"\n",
    "\n",
    "# 保存压缩后的倒排索引和词汇表\n",
    "save_compressed_data(\n",
    "    csv_file_path,\n",
    "    compressed_file_path,\n",
    "    vocabulary_file_path\n",
    ")\n",
    "\n",
    "# 处理电影倒排索引表\n",
    "csv_file_path = \"../data/movie_inverted_index_table.csv\"\n",
    "compressed_file_path = \"../data/movie_inverted_index_compressed.bin\"\n",
    "vocabulary_file_path = \"../data/movie_vocabulary.csv\"\n",
    "\n",
    "save_compressed_data(\n",
    "    csv_file_path,\n",
    "    compressed_file_path,\n",
    "    vocabulary_file_path\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现在压缩的倒排索引表上查询一个词项的倒排列表的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Zhenyu Bo\n",
    "# Date: 2024-11-07\n",
    "\n",
    "\"\"\"\n",
    "根据词典文件查找并解压缩特定词项的倒排索引。\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def variable_byte_decode(byte_data: bytes) -> list[int]:\n",
    "    \"\"\"\n",
    "    使用可变字节解码（Variable Byte Decoding）将字节序列解码为整数列表。\n",
    "\n",
    "    参数：\n",
    "    - byte_data: 压缩的字节序列。\n",
    "\n",
    "    返回：\n",
    "    - 解码后的整数列表。\n",
    "    \"\"\"\n",
    "    numbers = []\n",
    "    current_number = 0\n",
    "    for byte in byte_data:\n",
    "        if byte >= 128:\n",
    "            # 当最高位为1时，这是一个数字的第一个字节\n",
    "            # 先将之前的数字加入列表\n",
    "            if current_number != 0:\n",
    "                numbers.append(current_number)\n",
    "                current_number = 0\n",
    "            # 去掉最高位的1，得到数字的高位\n",
    "            current_number = (current_number << 7) | (byte - 128)\n",
    "        else:\n",
    "            # 当最高位为0时，这是一个数字的中间字节\n",
    "            current_number = (current_number << 7) | byte\n",
    "    # 将最后一个数字加入列表\n",
    "    numbers.append(current_number)\n",
    "    return numbers\n",
    "\n",
    "\n",
    "def reconstruct_doc_ids(gaps: list[int]) -> list[int]:\n",
    "    \"\"\"\n",
    "    根据文档间距列表重建原始的文档 ID 列表。\n",
    "\n",
    "    参数：\n",
    "    - gaps: 文档间距列表。\n",
    "\n",
    "    返回：\n",
    "    - 原始的文档 ID 列表。\n",
    "    \"\"\"\n",
    "    doc_ids = []\n",
    "    current_id = 0\n",
    "    for gap in gaps:\n",
    "        current_id += gap\n",
    "        doc_ids.append(current_id)\n",
    "    return doc_ids\n",
    "\n",
    "\n",
    "def load_vocabulary(vocabulary_file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    加载词典文件，将其内容存储在一个字典中。\n",
    "\n",
    "    参数：\n",
    "    - vocabulary_file_path: 词汇表文件路径，包含词项及其在倒排表中的字节偏移量和长度。\n",
    "\n",
    "    返回：\n",
    "    - 词典字典，键为词项，值为包含偏移量和长度的字典。\n",
    "    \"\"\"\n",
    "    vocabulary = {}\n",
    "    try:\n",
    "        with open(vocabulary_file_path, \"r\", encoding=\"UTF-8\") as f_vocab:\n",
    "            csv_reader = csv.DictReader(f_vocab)\n",
    "            for row in csv_reader:\n",
    "                word = row['word']\n",
    "                offset = int(row['offset'])\n",
    "                length = int(row['length'])\n",
    "                vocabulary[word] = {'offset': offset, 'length': length}\n",
    "    except IOError as e:\n",
    "        print(f\"文件操作失败: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"数据解析失败: {e}\")\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "def get_inverted_index_list(word: str, compressed_file_path=\"../data/book_inverted_index_compressed.bin\",\n",
    "                            vocabulary_file_path=\"../data/book_vocabulary.csv\") -> list[int]:\n",
    "    \"\"\"\n",
    "    根据给定的词项，从压缩的倒排表文件中提取并解压缩对应的倒排索引。\n",
    "\n",
    "    参数：\n",
    "    - word: 目标词项。\n",
    "    - compressed_file_path: 压缩后的倒排表二进制文件路径。\n",
    "    - vocabulary: 词典字典，包含词项及其在倒排表中的字节偏移量和长度。\n",
    "\n",
    "    返回：\n",
    "    - 解压缩后的文档 ID 列表。如果词项不存在，则返回空列表。\n",
    "    \"\"\"\n",
    "    # 检查文件是否存在\n",
    "    if not os.path.exists(compressed_file_path):\n",
    "        print(f\"压缩文件 '{compressed_file_path}' 不存在。\")\n",
    "        return\n",
    "    if not os.path.exists(vocabulary_file_path):\n",
    "        print(f\"词典文件 '{vocabulary_file_path}' 不存在。\")\n",
    "        return\n",
    "\n",
    "    # 加载词典\n",
    "    vocabulary = load_vocabulary(vocabulary_file_path)\n",
    "\n",
    "    if word not in vocabulary:\n",
    "        print(f\"词项 '{word}' 不存在于词典中。\")\n",
    "        return []\n",
    "\n",
    "    offset = vocabulary[word]['offset']\n",
    "    length = vocabulary[word]['length']\n",
    "\n",
    "    try:\n",
    "        with open(compressed_file_path, \"rb\") as f_bin:\n",
    "            f_bin.seek(offset)\n",
    "            compressed_bytes = f_bin.read(length)\n",
    "            gaps = variable_byte_decode(compressed_bytes)\n",
    "            doc_ids = reconstruct_doc_ids(gaps)\n",
    "            return doc_ids\n",
    "    except IOError as e:\n",
    "        print(f\"文件操作失败: {e}\")\n",
    "        return []\n",
    "    except (Exception) as e:\n",
    "        print(f\"解压缩过程中发生错误: {e}\")\n",
    "        return []"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "根据用户输入的词项，解压缩并显示其倒排索引。\n",
    "\"\"\"\n",
    "# 定义文件路径\n",
    "compressed_file_path = \"../data/book_inverted_index_compressed.bin\"\n",
    "vocabulary_file_path = \"../data/book_vocabulary.csv\"\n",
    "\n",
    "while True:\n",
    "    # 用户输入词项\n",
    "    word = input(\"请输入要查询的词项（输入 'exit' 退出）：\").strip()\n",
    "\n",
    "    # 检查是否退出\n",
    "    if word.lower() == 'exit':\n",
    "        print(\"退出查询。\")\n",
    "        break\n",
    "\n",
    "    # 获取并解压缩倒排索引\n",
    "    doc_ids = get_inverted_index_list(word, compressed_file_path, vocabulary_file_path)\n",
    "\n",
    "    if doc_ids:\n",
    "        print(f\"词项 '{word}' 对应的文档 ID 列表: {doc_ids}\")\n",
    "    else:\n",
    "        print(f\"词项 '{word}' 没有对应的文档或解压缩失败。\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用压缩后的倒排索引表进行布尔查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author: Zhenyu Bo\n",
    "# Date: 2024-11-14\n",
    "\n",
    "\"\"\"\n",
    "在经过可变长度编码压缩后的倒排索引表上执行布尔查询。\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# 倒排索引表，movie_inverted_index_table.csv \n",
    "# 全id表，Movie_id.txt\n",
    "# 词表，movie_words.csv 用于打印结果 目前格式同助教提供的selected_book_top_1200.csv\n",
    "\n",
    "def read_all_ids(file_path):\n",
    "    \"\"\"\n",
    "    读取所有ID，返回ID的集合。\n",
    "    \"\"\"\n",
    "    all_ids = set()\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            id = int(line.strip())\n",
    "            all_ids.add(id)\n",
    "    return all_ids\n",
    "\n",
    "def tokenize(expression):\n",
    "    \"\"\"\n",
    "    将布尔表达式分词。\n",
    "    \"\"\"\n",
    "    tokens = re.findall(r'AND|OR|NOT|\\w+|\\(|\\)', expression)\n",
    "    return tokens\n",
    "\n",
    "def infix_to_postfix(tokens):\n",
    "    \"\"\"\n",
    "    将中缀表达式转换为后缀表达式（逆波兰表达式）。\n",
    "    \"\"\"\n",
    "    precedence = {'NOT': 3, 'AND': 2, 'OR': 1}\n",
    "    output = []\n",
    "    operator_stack = []\n",
    "    operators = {'AND', 'OR', 'NOT'}\n",
    "    for token in tokens:\n",
    "        if token not in operators and token not in {'(', ')'}:\n",
    "            output.append(token)\n",
    "        elif token == '(':\n",
    "            operator_stack.append(token)\n",
    "        elif token == ')':\n",
    "            while operator_stack and operator_stack[-1] != '(':\n",
    "                output.append(operator_stack.pop())\n",
    "            operator_stack.pop()  # 弹出 '('\n",
    "        else:  # 操作符\n",
    "            while operator_stack and operator_stack[-1] != '(' and precedence.get(operator_stack[-1], 0) >= precedence.get(token, 0):\n",
    "                output.append(operator_stack.pop())\n",
    "            operator_stack.append(token)\n",
    "    while operator_stack:\n",
    "        output.append(operator_stack.pop())\n",
    "    return output\n",
    "\n",
    "def evaluate_postfix(postfix_tokens, compressed_file_path, vocabulary_file_path, all_ids):\n",
    "    \"\"\"\n",
    "    评估后缀表达式，返回符合条件的ID集合。\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    operators = {'AND', 'OR', 'NOT'}\n",
    "    for token in postfix_tokens:\n",
    "        if token not in operators:\n",
    "            inverted_index = get_inverted_index_list(token, compressed_file_path, vocabulary_file_path)\n",
    "            stack.append(set(inverted_index))\n",
    "        elif token == 'NOT' or token == 'not':\n",
    "            operand = stack.pop()\n",
    "            stack.append(all_ids - operand)\n",
    "        else:\n",
    "            right = stack.pop()\n",
    "            left = stack.pop()\n",
    "            if token == 'AND' or token == 'and':\n",
    "                stack.append(left & right)\n",
    "            elif token == 'OR' or token == 'or':\n",
    "                stack.append(left | right)\n",
    "    return stack.pop() if stack else set()\n",
    "\n",
    "def display_results(result_ids, words_df):\n",
    "    \"\"\"\n",
    "    根据查询结果的ID，从 DataFrame 中查找并打印ID和标签。\n",
    "    \"\"\"\n",
    "    df = words_df[words_df['id'].isin(result_ids)]\n",
    "    if not df.empty:\n",
    "        for _, row in df.iterrows():\n",
    "            id = row['id']\n",
    "            words = ast.literal_eval(row['words'])\n",
    "            print(f\"ID: {id}\")\n",
    "            print(f\"标签: {', '.join(words)}\\n\")\n",
    "    else:\n",
    "        print(\"没有符合条件的结果。\")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "# 主程序\n",
    "print(\"正在加载数据，请稍候...\")\n",
    "\n",
    "# 加载书籍数据\n",
    "book_all_ids = read_all_ids('../data/Book_id.txt')\n",
    "book_words_df = pd.read_csv('../data/book_words.csv', dtype={'id': int, 'words': str})\n",
    "\n",
    "# 加载电影数据\n",
    "movie_all_ids = read_all_ids('../data/Movie_id.txt')\n",
    "movie_words_df = pd.read_csv('../data/movie_words.csv', dtype={'id': int, 'words': str})\n",
    "\n",
    "print(\"数据加载完成！\")\n",
    "\n",
    "while True:\n",
    "    choice = input(\"请选择查询类型（1 - 书籍，2 - 电影）：\\n\")\n",
    "    if choice == '1':\n",
    "        compressed_file_path = \"../data/book_inverted_index_compressed.bin\"\n",
    "        vocabulary_file_path = \"../data/book_vocabulary.csv\"\n",
    "        all_ids = book_all_ids\n",
    "        words_df = book_words_df\n",
    "    elif choice == '2':\n",
    "        compressed_file_path = \"../data/movie_inverted_index_compressed.bin\"\n",
    "        vocabulary_file_path = \"../data/movie_vocabulary.csv\"\n",
    "        all_ids = movie_all_ids\n",
    "        words_df = movie_words_df\n",
    "    else:\n",
    "        print(\"输入错误，请输入 1 或 2。\")\n",
    "        continue  # 重新开始循环\n",
    "\n",
    "    expression = input(\"请输入布尔查询表达式：\\n\")\n",
    "    # 记录查询起始时间\n",
    "    start_time = time.time()\n",
    "    tokens = tokenize(expression)\n",
    "    postfix_tokens = infix_to_postfix(tokens)\n",
    "    result_ids = evaluate_postfix(postfix_tokens, compressed_file_path, vocabulary_file_path, all_ids)\n",
    "    # 计算查询耗时\n",
    "    elapsed_time = time.time() - start_time\n",
    "     \n",
    "    if result_ids:\n",
    "        print(\"查询结果：\\n\")\n",
    "        display_results(result_ids, words_df)\n",
    "    else:\n",
    "        print(\"没有符合条件的结果。\")\n",
    "    \n",
    "    print(\"查询耗时：{:.6f} 秒\".format(time.time() - start_time))\n",
    "\n",
    "    cont = input(\"是否继续查询？(Y/N): \")\n",
    "    if cont.strip().lower() != 'y':\n",
    "        print(\"感谢您的使用！\")\n",
    "        break  # 退出循环，结束程序\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
